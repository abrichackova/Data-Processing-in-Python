{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json \n",
    "from bs4 import BeautifulSoup \n",
    "import boto3 \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://ies-midterm.soulution.rocks/'\n",
    "d = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Login\n",
    "login_url = \"https://ies-midterm.soulution.rocks/login\"\n",
    "cuni_number = \"yourCUNInumber\"  \n",
    "\n",
    "login_payload = {\"cuni\": cuni_number}\n",
    "login_response = requests.post(login_url, json=login_payload)\n",
    "\n",
    "if login_response.status_code != 200:\n",
    "    print(\"Login failed:\", login_response.text)\n",
    "    exit()\n",
    "\n",
    "login_data = login_response.json()\n",
    "print(\"Personal Code:\", login_data.get(\"personal_code\"))\n",
    "\n",
    "codes = login_data.get(\"codes\", [])\n",
    "print(\"Received codes:\", codes)\n",
    "\n",
    "# Step 2: Get the data parts\n",
    "dataset = []\n",
    "data_url_template = \"https://ies-midterm.soulution.rocks/data/{}\"\n",
    "\n",
    "for code in codes:\n",
    "    success = False\n",
    "    while not success:\n",
    "        response = requests.get(data_url_template.format(code))\n",
    "        if response.status_code == 200:\n",
    "            data_piece = response.json()\n",
    "            print(f\"Data received from company: {data_piece['data']['company']}\")\n",
    "            dataset.extend(data_piece['data']['data'])\n",
    "            success = True\n",
    "        else:\n",
    "            print(f\"Error fetching {code}, retrying...\")\n",
    "            time.sleep(1)  # small delay before retrying\n",
    "\n",
    "# Final dataset ready\n",
    "print(f\"\\n Dataset complete. Total entries: {len(dataset)}\")\n",
    "\n",
    "# (Optional) Save the data to file\n",
    "with open(\"final_dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating csv\n",
    "import csv\n",
    "data ={\n",
    "  \"date\": \"2019-01-02\",\n",
    "  \"company\": \"ACME\",\n",
    "  \"open\": 50.0,\n",
    "  \"high\": 55.0,\n",
    "  \"low\": 48.5,\n",
    "  \"close\": 53.0,\n",
    "  \"adjclose\": 52.5,\n",
    "  \"volume\": 100000\n",
    "}\n",
    "\n",
    "with open('created_csv.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data)\n",
    "\n",
    "with open('people.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "#df.to_csv(\"cleaned_stock_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date range\n",
    "date_range = pd.date_range(start=\"2019-01-02\", end=\"2020-11-20\", freq='B')  # Business days\n",
    "\n",
    "# List of companies\n",
    "companies = ['CompanyA', 'CompanyB', 'CompanyC']\n",
    "\n",
    "# Initialize empty list to hold all the rows\n",
    "data = []\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "for company in companies:\n",
    "    # Simulate base price\n",
    "    price = np.random.uniform(50, 300)\n",
    "    for date in date_range:\n",
    "        # Simulate daily price movement\n",
    "        open_price = price + np.random.normal(0, 2)\n",
    "        high_price = open_price + np.random.normal(0, 2)\n",
    "        low_price = open_price - np.random.normal(0, 2)\n",
    "        close_price = low_price + np.random.normal(0, high_price - low_price)\n",
    "        adj_close = close_price + np.random.normal(-0.2, 0.2)\n",
    "        volume = np.random.randint(1_000_000, 6_000_000)\n",
    "\n",
    "        # Append row\n",
    "        data.append([\n",
    "            date.strftime('%Y-%m-%d'),\n",
    "            company,\n",
    "            round(open_price, 2),\n",
    "            round(high_price, 2),\n",
    "            round(low_price, 2),\n",
    "            round(close_price, 2),\n",
    "            round(adj_close, 2),\n",
    "            volume\n",
    "        ])\n",
    "\n",
    "        # Update price for next day\n",
    "        price = close_price\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    'Date', 'Company', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MIDTERM23-24Summer', 'Midterm_ZS_2021_2022.pdf', 'Midterm_Solved', '.DS_Store', 'midterm_my_solution_2021.ipynb', 'Midterm_ZS_2020-2021.pdf', '~$python.docx', 'python.docx', 'github-recovery-codes.txt', 'cleaned_stock_data.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/annabrichackova/Desktop/Python'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dowloading csv\n",
    "#working directory\n",
    "print(os.listdir('.'))\n",
    "os.chdir('/Users/annabrichackova/Desktop/Python')\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dowloading csv\n",
    "path = os.path.join(current_dir, 'cleaned_stock_data.csv')\n",
    "df=pd.read_csv('cleaned_stock_data.csv',sep=',',  on_bad_lines= 'skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LandContour'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
